#<h1 style='float:center'>spark Machine Learning 模块源码练习</h1>
#1.fpg频繁模式数据挖掘，包括关联规则、频繁模式、序列模式
####fpg包含三个模块:</br>
1.AssociationRules,输入数据集RDD[Item].把数据每项分裂成[前项,后项,频次]形式关联规则候选集.然后候选集和输入数据集进行join,并按照频次过滤,找出候选集<br>
2.FPGrowth频繁模式树Growth.其中把数据集吸写入到FPTree数据模型中,最后从FPTree抽取所有的符合频次的频繁集.<br>
#2.NLP特征提取
##TF-IDF
TF-IDF全称:term frequency - inverse doucument frequency(词频-逆向文件频率).<br>
TF-IDF是一种统计方法，用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度. <br>
####TF(词频)
TF在spark中,通过HashingTF实现,对每个词取Hash,并计算词频.
####IDF(逆向文件词频)
word2vec
把词转换成向量，并且具有近义词的vector接近的功能。


#3.NaiveBayes朴素贝叶斯分类
朴素贝叶斯是一种构建分类器的简单方法。该分类器模型会给问题实例分配用特征值表示的类标签，类标签取自有限集合。它不是训练这种分类器的单一算法，而是一系列基于相同原理的算法：所有朴素贝叶斯分类器都假定样本每个特征与其他特征都不相关。 举个例子，如果一种水果其具有红，圆，直径大概3英寸等特征，该水果可以被判定为是苹果。尽管这些特征相互依赖或者有些特征由其他特征决定，然而朴素贝叶斯分类器认为这些属性在判定该水果是否为苹果的概率分布上独立的。<br>

对于某些类型的概率模型，在有监督学习的样本集中能获取得非常好的分类效果。在许多实际应用中，朴素贝叶斯模型参数估计使用最大似然估计方法；换言之，在不用贝叶斯概率或者任何贝叶斯模型的情况下，朴素贝叶斯模型也能奏效。<br>

尽管是带着这些朴素思想和过于简单化的假设，但朴素贝叶斯分类器在很多复杂的现实情形中仍能够取得相当好的效果。尽管如此，有论文证明更新的方法（如提升树和随机森林）的性能超过了贝叶斯分类器。<br>

朴素贝叶斯分类器的一个优势在于只需要根据少量的训练数据估计出必要的参数（变量的均值和方差）。由于变量独立假设，只需要估计各个变量，而不需要确定整个协方差矩阵。<br>
